{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7a879a",
   "metadata": {},
   "source": [
    "# STEP 1 — Load CSV datafile (FAST I/O version)\n",
    "#\n",
    "# This cell:\n",
    "#  1) left memory_map at its (faster) default True\n",
    "#  2) supply a date_format, which lets pandas use a vectorized, fast path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22931fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33fa25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file and output file\n",
    "IN = Path(\"nytaxi2022.csv\")\n",
    "OUT = Path(\"nytaxi2022_cleaned.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9766659e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV fast-path…\n",
      "(39656098, 10)\n",
      "  tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  trip_distance  \\\n",
      "0  2022-01-01 00:35:40   2022-01-01 00:53:29              2.0           3.80   \n",
      "1  2022-01-01 00:33:43   2022-01-01 00:42:07              1.0           2.10   \n",
      "2  2022-01-01 00:53:21   2022-01-01 01:02:19              1.0           0.97   \n",
      "3  2022-01-01 00:25:21   2022-01-01 00:35:23              1.0           1.09   \n",
      "4  2022-01-01 00:36:48   2022-01-01 01:14:20              1.0           4.30   \n",
      "\n",
      "   RatecodeID  PULocationID  DOLocationID  payment_type  extra  total_amount  \n",
      "0           1           142           236             1    3.0     21.950001  \n",
      "1           1           236            42             1    0.5     13.300000  \n",
      "2           1           166           166             1    0.5     10.560000  \n",
      "3           1           114            68             2    0.5     11.800000  \n",
      "4           1            68           163             1    0.5     30.299999  \n"
     ]
    }
   ],
   "source": [
    "# Columns to be used\n",
    "use_cols = [\n",
    "    \"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"passenger_count\",\"trip_distance\",\n",
    "    \"RatecodeID\",\"PULocationID\",\"DOLocationID\",\"payment_type\",\"extra\",\"total_amount\"\n",
    "]\n",
    "\n",
    "\n",
    "# Exact datetime format (your file uses this)\n",
    "DT_FMT = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "\n",
    "# Small, memory-friendly dtypes (nullable ints for possible NAs)\n",
    "# If extension Int* feels slow on your box, switch Int* -> float32 and cast later.\n",
    "dtypes = {\n",
    "    \"passenger_count\": \"float32\",\n",
    "    \"trip_distance\":   \"float32\",\n",
    "    \"RatecodeID\":      \"Int8\",\n",
    "    \"PULocationID\":    \"Int16\",\n",
    "    \"DOLocationID\":    \"Int16\",\n",
    "    \"payment_type\":    \"Int8\",\n",
    "    \"extra\":           \"float32\",\n",
    "    \"total_amount\":    \"float32\",\n",
    "}\n",
    "\n",
    "print(\"Reading CSV fast-path…\")\n",
    "df = pd.read_csv(\n",
    "    IN,\n",
    "    usecols=use_cols,\n",
    "    dtype=dtypes,\n",
    "    parse_dates=[\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\"],\n",
    "    date_format=DT_FMT,      # <<< critical for speed\n",
    "    engine=\"c\",\n",
    "    memory_map=True\n",
    ")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0acf4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the original dataframe for reference\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3ec53",
   "metadata": {},
   "source": [
    "# STEP 2 — Clean up the dataset\n",
    "#\n",
    "# This cell:\n",
    "#  1) Drop rows with NA in critical columns\n",
    "#  2) Filter out invalid trips (trip_duration > 600 mins, trip_distance > 200 miles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda46939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropna: (39656098, 10)\n"
     ]
    }
   ],
   "source": [
    "# Basic filtering / feature engineering\n",
    "# 1) Drop rows with NA in critical columns\n",
    "df = df.dropna(subset=[\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"total_amount\"])\n",
    "print(\"After dropna:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6977ecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: (39021102, 11)\n"
     ]
    }
   ],
   "source": [
    "# Define trip duration in minutes\n",
    "df[\"trip_duration_min\"] = (\n",
    "    (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]).dt.total_seconds() / 60.0\n",
    ").astype(\"float32\")\n",
    "\n",
    "# 2) Filter out invalid trips\n",
    "df = df[\n",
    "    (df[\"trip_duration_min\"] > 0) & (df[\"trip_duration_min\"] < 600) &  # max 10 hours\n",
    "    (df[\"trip_distance\"] > 0) & (df[\"trip_distance\"] < 200)]  # max 200 miles\n",
    "\n",
    "print(\"After filtering:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e38cfa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time features\n",
    "df[\"hour\"] = df[\"tpep_pickup_datetime\"].dt.hour.astype(\"int16\")\n",
    "df[\"dow\"]  = df[\"tpep_pickup_datetime\"].dt.dayofweek.astype(\"int16\")\n",
    "df[\"is_weekend\"] = (df[\"dow\"]>=5).astype(\"int8\")\n",
    "\n",
    "# Categorical (small-cardinality) one-hots\n",
    "for col, cats in [(\"payment_type\", sorted(df[\"payment_type\"].dropna().unique())),\n",
    "                  (\"RatecodeID\",  sorted(df[\"RatecodeID\"].dropna().unique()))]:\n",
    "    dummies = pd.get_dummies(df[col].fillna(-1).astype(int), prefix=col)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "# Keep numeric/simple encodings\n",
    "num_cols = [\n",
    "    \"passenger_count\",\"trip_distance\",\"extra\",\"trip_duration_min\",\"hour\",\"dow\",\"is_weekend\",\n",
    "    \"PULocationID\",\"DOLocationID\"\n",
    "]\n",
    "one_hot_cols = [c for c in df.columns if c.startswith(\"payment_type_\") or c.startswith(\"RatecodeID_\")]\n",
    "X_cols = num_cols + one_hot_cols\n",
    "y_col = \"total_amount\"\n",
    "\n",
    "df = df.dropna(subset=X_cols+[y_col])\n",
    "X = df[X_cols].to_numpy(dtype=np.float32)\n",
    "y = df[y_col].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerics by train stats later; split first (stratification not needed)\n",
    "N = len(X)\n",
    "RNG = np.random.default_rng(42)\n",
    "idx = RNG.permutation(N)\n",
    "cut = int(0.7*N)\n",
    "train_idx, test_idx = idx[:cut], idx[cut:]\n",
    "\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "# Standardize numerics using train stats\n",
    "num_idx = [X_cols.index(c) for c in num_cols]\n",
    "mu = X_train[:, num_idx].mean(axis=0)\n",
    "sd = X_train[:, num_idx].std(axis=0) + 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8908ac2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved nytaxi2022_cleaned.npz  | rows: train=26416958, test=11321554\n"
     ]
    }
   ],
   "source": [
    "def apply_scale(A):\n",
    "    A = A.copy()\n",
    "    A[:, num_idx] = (A[:, num_idx]-mu)/sd\n",
    "    # scale location IDs (already inside num_cols) into [0,1] column-wise\n",
    "    pu_i, do_i = X_cols.index(\"PULocationID\"), X_cols.index(\"DOLocationID\")\n",
    "    for ii in [pu_i, do_i]:\n",
    "        col = A[:, ii]\n",
    "        mn, mx = col.min(), col.max()\n",
    "        A[:, ii] = (col - mn) / (mx - mn + 1e-8)\n",
    "    return A\n",
    "\n",
    "X_train = apply_scale(X_train)\n",
    "X_test  = apply_scale(X_test)\n",
    "\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "np.savez(OUT,\n",
    "         X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n",
    "         X_cols=np.array(X_cols, dtype=object), mu=mu, sd=sd, num_idx=np.array(num_idx))\n",
    "print(f\"Saved {OUT}  | rows: train={len(X_train)}, test={len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4041e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
